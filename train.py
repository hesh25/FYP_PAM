import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import OneHotEncoder
import joblib

print("Starting ML model training script...")

# Load all historical data from the log file generated by the portal
try:
    df = pd.read_csv('real_activity.log')
    # Add headers because our log file doesn't have them
    df.columns = ['hour', 'ip_is_local', 'action_type', 'user_role']
except FileNotFoundError:
    print("Error: real_activity.log not found. Please generate some data using portal.html first.")
    exit()

if df.empty:
    print("Log file is empty. No data to train on.")
    exit()

# Preprocess the data (same logic as before)
encoder = OneHotEncoder(handle_unknown='ignore')
X_encoded = encoder.fit_transform(df[['action_type', 'user_role']])
X_final = pd.concat([df[['hour', 'ip_is_local']], pd.DataFrame(X_encoded.toarray())], axis=1)
X_final.columns = X_final.columns.astype(str)

# Train the Isolation Forest model
model = IsolationForest(contamination=0.05, random_state=42) 
model.fit(X_final)

# Save the trained model and encoder to be used by the live app
joblib.dump(model, 'risk_model.joblib')
joblib.dump(encoder, 'encoder.joblib')

print("âœ… Model training complete. `risk_model.joblib` and `encoder.joblib` have been created/updated.")